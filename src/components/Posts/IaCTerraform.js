import React, { useEffect } from "react";
import styled from "styled-components";

// helpers
import { Analytics } from "../../helpers/analytics";

// animations
import SlideInBottom from "../../animations/SlideInBottom";

// components
import BackButton from "../Button/BackButton";
import { CodeBlockWithCopy } from "../Code/Code";
import CodeCarousel from "../CodeCarousel/CodeCarousel";

// layout
import {
  PageWrapper,
  PostTopBar,
  PostContainer as BasePostContainer,
  HeaderRow,
  IconWrapper,
  HeaderIcon,
} from '../BlogLayout/BlogLayout';

// typography
import {
  PageTitle,
  SectionHeading,
  SubSectionHeading,
  Paragraph,
  Strong,
  TextLink,
  TextList,
  TextListItem,
  InlineHighlight,
  IndentedTextList,
  IndentedTextListItem,
  TertiaryHeading,
} from "../Typography/Typography";

// icons
import { TerraformSVG } from '../../resources/styles/icons';

const AnimatedPostContainer = styled(BasePostContainer)`
  animation: ${SlideInBottom} 0.5s forwards;
`;

const verifyTf = `terraform version`;

const terraformFolderTree = `template-terraform-boilerplate/
├─ .github/
│  └─ workflows/
│     └─ terraform.yml
├─ cli/
│  ├─ package.json
│  └─ src/
│     ├─ index.js
│     ├─ commands/
│     │  ├─ bootstrap.js
│     │  └─ oidc.js
│     └─ lib/
│        ├─ cloudformation.js
│        └─ render.js
├─ bootstrap/
│  └─ cfn/
│     ├─ state.yml
│     ├─ iam.yml
│     └─ oidc.yml
├─ infra/
│  ├─ env/
│  │  └─ <aws-account>/
│  │     ├─ env.tfvars
│  │     ├─ main.tf
│  │     ├─ outputs.tf
│  │     ├─ providers.tf
│  │     ├─ variables.tf
│  │     └─ backend.tf
│  ├─ modules/
│  │  └─ <module-name>/
│  │     ├─ main.tf
│  │     ├─ outputs.tf
│  │     └─ variables.tf
│  └─ scripts/
│     ├─ fmt.sh
│     ├─ validate.sh
│     ├─ plan.sh
│     ├─ apply.sh
│     ├─ use-env.sh
│     └─ whoami.sh
├─ .gitignore
├─ package.json
└─ README.md`;

const envMainTf = `/*
main.tf (environment root)
- This is the deployable entry point for an environment.
- Keep it readable: wire modules together, pass variables, expose outputs.
*/

module "example_bucket" {
  source = "../../modules/example-s3-bucket"

  project     = var.project
  environment = var.environment

  # Example input for the module
  bucket_suffix = "uploads"
}`;

const envVariablesTf = `/*
variables.tf (environment root)
- Defines the inputs this environment expects.
- Keep types + descriptions tight so usage is obvious and mistakes are caught early.
*/

variable "project" {
  type        = string
  description = "Project name used for naming/tagging."
}

variable "environment" {
  type        = string
  description = "A label for this deployable root (often matches the folder name under infra/env/)."
}

variable "aws_region" {
  type        = string
  description = "AWS region to deploy into."
  default     = "eu-west-2"
}`;


const envTfvars = `/*
env.tfvars (environment root)
- Values specific to this deployable root.
- Keeps main.tf identical across accounts/environments.
*/

project     = "template-terraform-boilerplate"
environment = "<aws-account>"
aws_region  = "eu-west-2"`;



const envProvidersTf = `/*
providers.tf (environment root)
- Configures provider(s) used by this environment.
- Makes the deployment context explicit (region/account/role).
- Providers are configured at the root and inherited by modules.
*/

terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region = var.aws_region

  default_tags {
    tags = {
      Project     = var.project
      Environment = var.environment
      ManagedBy   = "terraform"
    }
  }
}`;


const envOutputsTf = `/*
outputs.tf (environment root)
- Outputs are the values you want to quickly grab after apply.
- Think: URLs, IDs, ARNs, bucket names, etc.
*/

output "uploads_bucket_name" {
  description = "Name of the uploads S3 bucket."
  value       = module.example_bucket.bucket_name
}`;


const envBackendTf = `/*
backend.tf (environment root)
- Backend values cannot use variables, and you don't want account-specific state settings committed to Git.
- This template keeps backend.tf minimal and injects real values at init time using infra/backend.hcl (generated by the CLI).
*/

terraform {
  backend "s3" {}
}`;

const moduleMainTf = `/*
main.tf (module)
- Modules are reusable building blocks.
- Keep modules focused: one responsibility, clear inputs/outputs.
*/

resource "aws_s3_bucket" "this" {
  bucket = "\${var.project}-\${var.environment}-\${var.bucket_suffix}"
}`;

const moduleVariablesTf = `/*
variables.tf (module)
- Inputs required by the module.
- Keep them minimal and well-described.
*/

variable "project" {
  type        = string
  description = "Project name used for naming/tagging."
}

variable "environment" {
  type        = string
  description = "Environment name (aws-account)."
}

variable "bucket_suffix" {
  type        = string
  description = "Suffix used to build the bucket name (e.g., uploads)."
}`;

const moduleOutputsTf = `/*
outputs.tf (module)
- Outputs are how other parts of the system connect to this module.
*/

output "bucket_name" {
  description = "Name of the S3 bucket created by this module."
  value       = aws_s3_bucket.this.bucket
}`;

const scriptFmt = `#!/usr/bin/env bash
set -euo pipefail

# fmt.sh
# - Formats Terraform code under infra/ recursively.
# - Keeps diffs clean and matches what CI enforces.
#
# Usage:
#   infra/scripts/fmt.sh

ROOT_DIR="$(cd "$(dirname "\${BASH_SOURCE[0]}")/.." && pwd)"
cd "$ROOT_DIR"

terraform fmt -recursive
echo "fmt complete"`;


const scriptValidate = `#!/usr/bin/env bash
set -euo pipefail

# validate.sh
# - Local quality gate (CI-like) for a deployable root under infra/env/<aws-account>
# - Includes checks:
#   1) terraform fmt -check (style gate, does not modify files)
#   2) terraform validate (syntax + internal consistency)
#   3) tflint (provider-aware linting)
#
# Usage:
#   infra/scripts/validate.sh <aws-account>
#
# Install tflint:
#   https://github.com/terraform-linters/tflint

ENVIRONMENT="\${1:-}"
if [ -z "$ENVIRONMENT" ]; then
  echo "Usage: infra/scripts/validate.sh <aws-account>"
  exit 1
fi

ROOT_DIR="$(cd "$(dirname "\${BASH_SOURCE[0]}")/.." && pwd)"
ENV_DIR="$ROOT_DIR/env/$ENVIRONMENT"

if [ ! -d "$ENV_DIR" ]; then
  echo "Environment folder not found: $ENV_DIR"
  echo "Usage: infra/scripts/validate.sh <aws-account>"
  exit 1
fi

echo "Validate (fmt check → terraform validate → tflint)"
echo "Target: $ENVIRONMENT"
echo ""

echo "→ terraform fmt (check)"
cd "$ROOT_DIR"
terraform fmt -recursive -check
echo "fmt check passed"
echo ""

echo "→ terraform validate"
cd "$ENV_DIR"
terraform init -backend=false -input=false >/dev/null
terraform validate
echo "terraform validate passed"
echo ""

echo "→ tflint"
if ! command -v tflint >/dev/null 2>&1; then
  echo "tflint is not installed"
  echo "Install: https://github.com/terraform-linters/tflint"
  exit 1
fi

cd "$ROOT_DIR"
tflint --recursive
echo "tflint passed"
echo ""

echo "validate complete for target: $ENVIRONMENT"`;

const scriptPlan = `#!/usr/bin/env bash
set -euo pipefail

# plan.sh
# - Creates a plan for a chosen deployable root under infra/env/<aws-account>.
# - Uses env.tfvars to supply values.
# - Outputs a tfplan file so apply uses an exact, reviewed plan.
#
# Usage:
#   infra/scripts/plan.sh <aws-account>

ENVIRONMENT="\${1:-}"
if [ -z "$ENVIRONMENT" ]; then
  echo "Usage: infra/scripts/plan.sh <aws-account>"
  exit 1
fi

ROOT_DIR="$(cd "$(dirname "\${BASH_SOURCE[0]}")/.." && pwd)"
ENV_DIR="$ROOT_DIR/env/$ENVIRONMENT"

if [ ! -d "$ENV_DIR" ]; then
  echo "Environment folder not found: $ENV_DIR"
  echo "Usage: infra/scripts/plan.sh <aws-account>"
  exit 1
fi

echo "Plan"
echo "Target: $ENVIRONMENT"
echo ""

cd "$ENV_DIR"

terraform init -input=false -backend-config=../../backend.hcl

terraform plan -input=false \\
  -var-file="env.tfvars" \\
  -out="tfplan"

echo "plan complete for target: $ENVIRONMENT"
echo "Plan saved to: $ENV_DIR/tfplan"`;

const scriptApply = `#!/usr/bin/env bash
set -euo pipefail

# apply.sh
# - Applies a previously generated plan file (tfplan).
# - Avoids "surprise applies" and matches a safer CI pattern.
#
# Usage:
#   infra/scripts/apply.sh <aws-account>

ENVIRONMENT="\${1:-}"
if [ -z "$ENVIRONMENT" ]; then
  echo "Usage: infra/scripts/apply.sh <aws-account>"
  exit 1
fi

ROOT_DIR="$(cd "$(dirname "\${BASH_SOURCE[0]}")/.." && pwd)"
ENV_DIR="$ROOT_DIR/env/$ENVIRONMENT"

if [ ! -d "$ENV_DIR" ]; then
  echo "Environment folder not found: $ENV_DIR"
  echo "Usage: infra/scripts/apply.sh <aws-account>"
  exit 1
fi

echo "Apply"
echo "Target: $ENVIRONMENT"
echo ""

cd "$ENV_DIR"

if [ ! -f "tfplan" ]; then
  echo "No tfplan found in $ENV_DIR"
  echo "Run: infra/scripts/plan.sh $ENVIRONMENT"
  exit 1
fi

terraform apply -input=false "tfplan"
echo "apply complete for target: $ENVIRONMENT"`;

const awsConfigExample = `# ~/.aws/config
#
# This file stores AWS CLI profile configuration (not secret credentials).
# Terraform and the AWS CLI both read these profiles, so switching context locally
# can be as simple as setting AWS_PROFILE=<aws-account>.
#
# The profile name can match your infra/env/<aws-account>/ folder name.

[default]
region = eu-west-2

[profile <aws-account-a>]
region = eu-west-2
role_arn = arn:aws:iam::111111111111:role/TerraformExecutionRole
source_profile = default

[profile <aws-account-b>]
region = eu-west-2
role_arn = arn:aws:iam::222222222222:role/TerraformExecutionRole
source_profile = default`;


const awsCredentialsExample = `# ~/.aws/credentials
#
# This file stores credential material for profiles.
# In many teams, "base" is an AWS SSO profile instead of static keys.
# This example uses placeholders so you can see the shape.
#
# "default" credentials are used when AWS_PROFILE isn't set.
# In many teams this is replaced by AWS SSO rather than static keys.

[default]
aws_access_key_id = YOUR_ACCESS_KEY_ID
aws_secret_access_key = YOUR_SECRET_ACCESS_KEY`;

const scriptUseEnv = `#!/usr/bin/env bash
set -euo pipefail

# use-env.sh
# - Switches local AWS context by setting AWS_PROFILE=<aws-account>.
# - Use with "source" so the variable persists in your current shell session.
#
# Usage:
#   source infra/scripts/use-env.sh <aws-account>
#
# Notes:
# - Assumes AWS profiles are configured in ~/.aws/config
# - Region is set here for convenience and can be overridden

ENVIRONMENT="\${1:-}"
if [ -z "$ENVIRONMENT" ]; then
  echo "Usage: source infra/scripts/use-env.sh <aws-account>"
  return 1 2>/dev/null || exit 1
fi

export AWS_PROFILE="$ENVIRONMENT"

# Optional: keep region explicit for Terraform + AWS CLI
export AWS_REGION="\${AWS_REGION:-eu-west-2}"
export AWS_DEFAULT_REGION="\${AWS_DEFAULT_REGION:-$AWS_REGION}"

echo "Switched AWS context"
echo "AWS_PROFILE=$AWS_PROFILE"
echo ""
echo "Next:"
echo "  cd infra/env/$ENVIRONMENT"
echo "  terraform init -backend-config=../../backend.hcl"
echo "  terraform plan -var-file=env.tfvars"`;

const scriptWhoAmI = `#!/usr/bin/env bash
set -euo pipefail

# whoami.sh
# - Prints the current AWS identity (account + principal ARN).
# - Useful before plan/apply, especially when switching environments.
#
# Usage:
#   infra/scripts/whoami.sh
#
# Notes:
# - Requires jq for prettier output

if ! command -v jq >/dev/null 2>&1; then
  echo "jq is required for this script (brew install jq / apt-get install jq)"
  exit 1
fi

aws sts get-caller-identity | jq`;

const terraformRoleTrustPolicyExample = `{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "AllowAssumeFromTrustedPrincipal",
      "Effect": "Allow",
      "Principal": {
        "AWS": "arn:aws:iam::111111111111:role/YourTrustedRoleOrUser"
      },
      "Action": "sts:AssumeRole"
    }
  ]
}`;

const backendExample = `/*
backend.hcl (generated by the CLI)
- Not committed to Git.
- Injected at init time so backend values stay account-specific and portable.
*/

bucket         = "<state-bucket-name>"
key            = "template-terraform-boilerplate/<aws-account>/terraform.tfstate"
region         = "eu-west-2"
dynamodb_table = "<lock-table-name>"
encrypt        = true
role_arn       = "arn:aws:iam::<account-id>:role/<terraform-execution-role>"`;

const stateKeyConvention = `/*
State key convention (recommended)
- Keep state keys predictable and scoped to the deployable root folder.
- A common pattern is:
  <project>/<aws-account>/terraform.tfstate

Example:
- template-terraform-boilerplate/<aws-account>/terraform.tfstate
*/`;


const githubTerraformWorkflow = `name: Terraform

on:
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      target:
        description: "Environment folder under infra/env/ (e.g. dev-account, staging-account, prod-account)"
        required: true
        type: string

permissions:
  id-token: write
  contents: read
  pull-requests: write

concurrency:
  group: terraform-\${{ github.ref }}
  cancel-in-progress: true

env:
  TF_IN_AUTOMATION: "true"
  AWS_REGION: "eu-west-2"

jobs:
  plan:
    name: Plan (\${{ matrix.environment }})
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    strategy:
      fail-fast: false
      matrix:
        # Replace these with the folder names under infra/env/
        environment: [account-a, account-b]

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          # Recommended: store AWS_ROLE_ARN as an Environment Secret and set environment: below
          role-to-assume: \${{ secrets.AWS_ROLE_ARN }}
          aws-region: \${{ env.AWS_REGION }}

      - name: Validate (fmt check + validate + tflint)
        run: bash infra/scripts/validate.sh \${{ matrix.environment }}

      - name: Plan
        run: bash infra/scripts/plan.sh \${{ matrix.environment }}

      - name: Upload plan artifact
        uses: actions/upload-artifact@v4
        with:
          name: tfplan-\${{ matrix.environment }}
          path: infra/env/\${{ matrix.environment }}/tfplan
          if-no-files-found: error

  apply:
    name: Apply (\${{ inputs.environment }})
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch'
    environment: \${{ inputs.environment }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: \${{ secrets.AWS_ROLE_ARN }}
          aws-region: \${{ env.AWS_REGION }}

      - name: Validate (fmt check + validate + tflint)
        run: bash infra/scripts/validate.sh \${{ inputs.environment }}

      - name: Plan
        run: bash infra/scripts/plan.sh \${{ inputs.environment }}

      - name: Apply
        run: bash infra/scripts/apply.sh \${{ inputs.environment }}
`;

const bootstrapOverview = `/*
Bootstrap (why it exists)
- Terraform needs a backend for remote state (S3 + DynamoDB locking).
- But Terraform cannot safely create its own backend on the very first run.
- So this template ships a tiny CLI that bootstraps the prerequisites:
  - S3 bucket (state storage)
  - DynamoDB table (state locking)
  - IAM execution role (assumed locally or by CI)
  - Optional: GitHub OIDC role for Actions
- It then generates infra/backend.hcl so terraform init works immediately.
*/`;

const bootstrapCommands = `# from repo root

# 1) Bootstrap AWS prerequisites into the currently authenticated account
#    (switch AWS_PROFILE / credentials to target a different account)
npm run tf:bootstrap -- --target <aws-account> --region eu-west-2

# 2) Initialise Terraform using the generated backend config
cd infra/env/<aws-account>
terraform init -backend-config=../../backend.hcl

# 3) Validate / plan / apply using the scripts
bash ../../scripts/validate.sh <aws-account>
bash ../../scripts/plan.sh <aws-account>
bash ../../scripts/apply.sh <aws-account>`;

const bootstrapFolderTree = `template-terraform-boilerplate/
├─ cli/
│  ├─ package.json
│  └─ src/
│     ├─ index.js
│     ├─ commands/
│     │  ├─ bootstrap.js
│     │  └─ oidc.js
│     └─ lib/
│        ├─ cloudformation.js
│        └─ render.js
├─ bootstrap/
│  └─ cfn/
│     ├─ state.yml
│     ├─ iam.yml
│     └─ oidc.yml
└─ infra/
   ├─ backend.hcl (generated, gitignored)
   └─ env/ ...`;

const backendHclExample = `# infra/backend.hcl (generated by the CLI)
bucket         = "<state-bucket-name>"
key            = "template-terraform-boilerplate/<aws-account>/terraform.tfstate"
region         = "eu-west-2"
dynamodb_table = "<lock-table-name>"
encrypt        = true
role_arn       = "arn:aws:iam::<account-id>:role/<terraform-execution-role>"`;

const backendTfRecommended = `/*
backend.tf (environment root)
- Keep backend config out of Git.
- Backend values cannot use variables, so this file stays minimal.
- You pass real values via -backend-config=../../backend.hcl (generated by CLI).
*/

terraform {
  backend "s3" {}
}`;

const packageJsonScripts = `{
  "name": "template-terraform-boilerplate",
  "private": true,
  "scripts": {
    "tf:bootstrap": "node cli/src/index.js bootstrap",
    "tf:oidc": "node cli/src/index.js oidc"
  }
}`;

const namingAndSingleAccountNote = `/*
Template note: single-account bootstrap + naming
- This template's CLI bootstraps prerequisites into the AWS account you're currently authenticated to.
- Want another account? Switch AWS_PROFILE (or pass --profile) and run the command again.
- Bucket/table/role names in this post are examples only.
  The CLI can generate safe defaults, and you can override names explicitly when you want full control.
*/`;

const IaCTerraform = () => {
  useEffect(() => {
    Analytics.event('blog_opened', { slug: 'infrastructure-as-code-with-terraform' });
  }, []);

  return (
    <PageWrapper>
      <PostTopBar>
        <BackButton />
      </PostTopBar>

      <AnimatedPostContainer>
        <HeaderRow>
          <PageTitle>Infrastructure as Code (IaC) with Terraform</PageTitle>
          <IconWrapper>
            <HeaderIcon>
              <TerraformSVG />
            </HeaderIcon>
          </IconWrapper>
        </HeaderRow>

        <Paragraph>
          In this post, we're going to build a Terraform template repo and work through the core workflow (init, plan, apply).
          We'll cover how to structure a project sensibly, and how to take the same setup from local development into CI and
          multiple environments.
        </Paragraph>

        <Paragraph>
          We'll start by organising the repo in a way that's easy to understand, then introduce Terraform concepts as they become relevant.
        </Paragraph>

        <Paragraph>
          Here is a link to the boilerplate that works locally and sets you up nicely for CI and multiple environments - <TextLink
            href="https://github.com/heyitsmeharv/template-terraform-boilerplate"
            target="_blank"
            rel="noreferrer"
          >
            template-terraform-boilerplate
          </TextLink>
        </Paragraph>

        <SectionHeading>What is Terraform?</SectionHeading>

        <Paragraph>
          Terraform is an <Strong>Infrastructure as Code</Strong> tool. It's how teams create repeatable environments,
          manage changes safely, and keep infrastructure consistent across accounts and regions.
        </Paragraph>

        <SectionHeading>Install Terraform (and verify)</SectionHeading>

        <Paragraph>
          Terraform is distributed as a single CLI tool. The easiest way to install it is usually through your system package manager, but you can also
          download the binary directly if you prefer.
        </Paragraph>

        <Paragraph>
          If you want the most up-to-date steps for your OS, these are the official docs I'd follow:
          {" "}
          <TextLink
            href="https://developer.hashicorp.com/terraform/install"
            target="_blank"
            rel="noreferrer"
          >
            Terraform install page
          </TextLink>
          {" "}
          and
          {" "}
          <TextLink
            href="https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli"
            target="_blank"
            rel="noreferrer"
          >
            Install Terraform CLI tutorial
          </TextLink>
          .
        </Paragraph>

        <SubSectionHeading>Verify the CLI is working</SubSectionHeading>
        <Paragraph>
          Once Terraform is installed, run the commands below. If they work, you're ready to move on.
        </Paragraph>

        <CodeBlockWithCopy code={verifyTf} />

        <SectionHeading>Repository Structure</SectionHeading>

        <Paragraph>
          Before we write any Terraform, we're going to agree on a structure that stays easy to navigate as the project grows. Everything Terraform-related
          lives under <InlineHighlight>infra/</InlineHighlight>, so the rest of the repo (app code, docs, tooling) can evolve independently.
        </Paragraph>

        <Paragraph>
          This layout separates two concerns: <Strong>environment roots</Strong> (where we actually run Terraform) and <Strong>modules</Strong> (reusable
          building blocks). That separation is what keeps your repo from turning into one huge folder.
        </Paragraph>

        <SubSectionHeading>High-level layout</SubSectionHeading>
        <CodeBlockWithCopy code={terraformFolderTree} />

        <SubSectionHeading>.github/workflows/</SubSectionHeading>
        <Paragraph>
          This is where your CI workflow lives. Later on, we'll add a workflow that runs <InlineHighlight>terraform fmt</InlineHighlight>,{" "}
          <InlineHighlight>validate</InlineHighlight> and <InlineHighlight>plan</InlineHighlight> on pull requests, and only runs{" "}
          <InlineHighlight>apply</InlineHighlight> on merges to main. Keeping workflows next to the code makes your infrastructure changes reviewable and
          repeatable. I have a separate blog post going through GitHub's CI/CD which you can find here if you want a rundown on how that works{" "}
          <TextLink href="/blog/github-ci-cd">GitHub CI/CD</TextLink>.
        </Paragraph>

        <SubSectionHeading>infra/env/</SubSectionHeading>
        <Paragraph>
          Each folder under <InlineHighlight>infra/env/</InlineHighlight> is the deployable Terraform root. This is the folder you{" "}
          <Strong>cd into</Strong> when you run Terraform commands for that environment.
        </Paragraph>

        <Paragraph>
          Typically you create a folder for each AWS account you deploy into. Let's run through each file
          you would find in the environment folder:
        </Paragraph>

        <CodeCarousel
          items={[
            {
              title: "main.tf",
              description: "Environment entry point where you wire modules together and keep the overall intent readable.",
              code: envMainTf,
            },
            {
              title: "variables.tf",
              description: "Typed inputs for the environment so configuration stays explicit and mistakes are caught early.",
              code: envVariablesTf,
            },
            {
              title: "env.tfvars",
              description: "Environment-specific values so the Terraform code can stay the same across environments.",
              code: envTfvars,
            },
            {
              title: "providers.tf",
              description: "Provider configuration for this environment (region/account context), inherited by modules.",
              code: envProvidersTf,
            },
            {
              title: "outputs.tf",
              description: "The important values you want after apply (names, IDs, URLs) without digging through state.",
              code: envOutputsTf,
            },
            {
              title: "backend.tf",
              description: "Minimal backend block. Real state settings are injected via infra/backend.hcl at init time.",
              code: envBackendTf,
            },
          ]}
        />

        <SubSectionHeading>infra/modules/</SubSectionHeading>
        <Paragraph>
          Modules are reusable pieces of infrastructure you can wire together from an environment root. If an environment folder starts to feel like a
          long list of resources, it's usually better to break that up into multiple modules.
        </Paragraph>

        <Paragraph>
          Notice how we pass attributes from the main.tf in the environment folder to be used as variables inside our module.
        </Paragraph>

        <CodeCarousel
          items={[
            {
              title: "main.tf",
              description: "The resources this module creates (keep modules small and single-purpose).",
              code: moduleMainTf,
            },
            {
              title: "variables.tf",
              description: "Inputs the module needs so it stays reusable across environments.",
              code: moduleVariablesTf,
            },
            {
              title: "outputs.tf",
              description: "What the module returns so other parts of the system can connect to it cleanly.",
              code: moduleOutputsTf,
            }
          ]}
        />

        <SubSectionHeading>infra/scripts/</SubSectionHeading>

        <Paragraph>
          These scripts are optional, but they make local development feel the same as CI. GitHub Actions will run the workflow end-to-end, but when you're
          working locally it's still useful to have a consistent way to format, validate, plan, and apply - especially once you introduce multiple environments.
        </Paragraph>

        <Paragraph>
          The main idea is that whether you're working locally or in CI, you're running the same steps in the same order:{" "}
          <InlineHighlight>fmt</InlineHighlight> → <InlineHighlight>validate</InlineHighlight> → <InlineHighlight>plan</InlineHighlight> →{" "}
          <InlineHighlight>apply</InlineHighlight>.
        </Paragraph>

        <Paragraph>
          I will go through the scripts usage more thoroughly in it's own section <Strong>(Local Development)</Strong> as to not to distract from
          the purpose of this topic.
        </Paragraph>

        <SubSectionHeading>repo-level files</SubSectionHeading>
        <Paragraph>
          <Strong>.gitignore</Strong> should exclude .terraform state files, and plan files so you never commit
          sensitive or noisy artifacts.
        </Paragraph>
        <Paragraph>
          <Strong>README.md</Strong> becomes your "how to run this repo" entry point: what it deploys, how environments work, and the basic commands.
        </Paragraph>
        <Paragraph>
          <Strong>package.json</Strong> is optional, but if you're already using Node tooling for your projects it can be a nice place to standardise
          scripts (for example: running Terraform scripts, formatting, linting, and CI helpers) in one familiar interface.
        </Paragraph>

        <SectionHeading>Local Development</SectionHeading>
        <Paragraph>
          We touched on the topics of scripts above in the Repository Structure about how they could be used to help run your terraform locally. What is
          also handy is the ability to maintain a local setup when working in multiple environments.
        </Paragraph>

        <Paragraph>
          Locally, we'll use{" "} <Strong>AWS profiles per environment</Strong> so switching between AWS accounts is explicit and low-risk.
        </Paragraph>

        <SubSectionHeading>AWS profiles per environment</SubSectionHeading>

        <Paragraph>
          The approach is simple: create one AWS CLI profile per environment in{" "}
          <InlineHighlight>~/.aws/config</InlineHighlight>, and store your base credentials in{" "}
          <InlineHighlight>~/.aws/credentials</InlineHighlight>.
          Terraform and the AWS CLI both understand these files. The AWS docs cover the file locations and formats in detail:
          {" "}
          <TextLink href="https://docs.aws.amazon.com/cli/v1/userguide/cli-configure-files.html" target="_blank" rel="noreferrer">
            AWS CLI config & credentials files
          </TextLink>
          {" "}
          and
          {" "}
          <TextLink href="https://docs.aws.amazon.com/cli/v1/userguide/cli-chap-configure.html" target="_blank" rel="noreferrer">
            Configuring the AWS CLI
          </TextLink>
          .
        </Paragraph>

        <Paragraph>
          In a team setup, you'll typically assume a Terraform role per environment/account. AWS roles are split into two parts: a{" "}
          <InlineHighlight>trust policy</InlineHighlight> (who can assume the role) and a{" "}
          <InlineHighlight>permissions policy</InlineHighlight> (what the role can do).
        </Paragraph>

        <Paragraph>
          If you need a refresher, the best starting point:
          {" "}
          <TextLink href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html" target="_blank" rel="noreferrer">
            IAM roles overview
          </TextLink>
          {" "}
          and
          {" "}
          <TextLink href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-custom.html" target="_blank" rel="noreferrer">
            Create a role with a custom trust policy
          </TextLink>
          .
          {" "}
          Alternatively you can look at my
          {" "}
          <TextLink href="https://www.heyitsmeharv.com/blog/aws-identity-access-management" target="_blank" rel="noreferrer">
            AWS Identity and Access Management (IAM) blog post
          </TextLink>
          .
        </Paragraph>

        <CodeCarousel
          items={[
            {
              title: "~/.aws/config",
              description: `This file stores AWS CLI profile configuration (not secret credentials).`,
              code: awsConfigExample,
            },
            {
              title: "~/.aws/credentials",
              description: "This file stores credentials for profiles. This file should never be shared or else you risk losing your account!",
              code: awsCredentialsExample,
            },
            {
              title: "Terraform role trust policy",
              description: `This is a simple example of a trust policy that allows a specific principal to assume the role.
              The actual principal will depend on your setup (an IAM user, an SSO role, or a role in another account). The key idea is: trust policy controls 
              who can assume, permissions policy controls what they can do.`,
              code: terraformRoleTrustPolicyExample,
            }
          ]}
        />

        <SubSectionHeading>Scripts</SubSectionHeading>
        <Paragraph>
          These scripts assume you're using named AWS profiles. The main one you'll use is{" "}
          <InlineHighlight>use-env.sh</InlineHighlight>, which sets <InlineHighlight>AWS_PROFILE</InlineHighlight> for your shell session.
          From there, Terraform commands run in the correct account/role context.
        </Paragraph>

        <CodeCarousel
          items={[
            {
              title: "use-env.sh",
              description: "Switches AWS context locally by setting AWS_PROFILE to match a environment name.",
              code: scriptUseEnv,
            },
            {
              title: "whoami.sh",
              description: "Prints your active AWS identity (account/role) so you don't plan/apply in the wrong place.",
              code: scriptWhoAmI,
            },
            {
              title: "fmt.sh",
              description: "Formats Terraform code under infra so the code stay clean.",
              code: scriptFmt,
            },
            {
              title: "validate.sh",
              description: "The local quality gate (fmt check + validate + tflint) before you generate a plan.",
              code: scriptValidate,
            },
            {
              title: "plan.sh",
              description: "Creates a saved plan file using env.tfvars so changes can be reviewed.",
              code: scriptPlan,
            },
            {
              title: "apply.sh",
              description: "Applies the saved plan file so you deploy exactly what you planned.",
              code: scriptApply,
            },
          ]}
        />

        <Paragraph>
          Once we introduce GitHub Actions, the workflow will run these same steps automatically. The scripts are just there to keep your local workflow
          consistent and safe, especially when you're switching environments.
        </Paragraph>

        <SubSectionHeading>Backend conventions</SubSectionHeading>

        <Paragraph>
          You'll see backend config kept in a dedicated <InlineHighlight>backend.tf</InlineHighlight> at the environment root. I like this because it makes state
          behaviour explicit per environment, and keeps it separate from provider configuration.
        </Paragraph>

        <Paragraph>
          The key detail is the <InlineHighlight>key</InlineHighlight>. That's the path inside the bucket where the state file lives. Use a predictable convention
          so it's always obvious which environment you're looking at.
        </Paragraph>

        <CodeBlockWithCopy code={stateKeyConvention} />

        <SubSectionHeading>Backend example</SubSectionHeading>

        <Paragraph>
          This is the standard AWS pattern: S3 stores the state file, and DynamoDB provides a lock so concurrent applies don't collide.
          In this template, the real backend values live in <InlineHighlight>infra/backend.hcl</InlineHighlight> (generated by the CLI).
        </Paragraph>
        <CodeBlockWithCopy code={backendExample} />

        <SubSectionHeading>What remote state solves</SubSectionHeading>

        <TextList>
          <TextListItem>
            <Strong>Shared source of truth</Strong> - your laptop and CI both read/write the same state, so you don't end up with competing copies.
          </TextListItem>
          <TextListItem>
            <Strong>Locking</Strong> - prevents two applies happening at once, which is one of the fastest ways to corrupt state.
          </TextListItem>
          <TextListItem>
            <Strong>Environment isolation</Strong> - each environment gets its own separate state file, even if they share the same module code.
          </TextListItem>
        </TextList>

        <SubSectionHeading>What changes locally when you enable a backend</SubSectionHeading>
        <Paragraph>
          Once <InlineHighlight>backend.tf</InlineHighlight> is present, <InlineHighlight>terraform init</InlineHighlight> will initialise the backend and move your
          state into it. From that point on, <InlineHighlight>plan</InlineHighlight> and <InlineHighlight>apply</InlineHighlight> operate against remote state —
          which is exactly what you want for CI.
        </Paragraph>

        <Paragraph>
          Now we've finished looking at local development, we can now look into integrating the same flow into GitHub Actions,
          but putting processes in place so that pull requests generate plans automatically, and main branch merges are the only thing that can apply the terraform.
        </Paragraph>

        <SectionHeading>Bootstrap AWS prerequisites</SectionHeading>

        <Paragraph>
          Remote state is non-negotiable once you introduce CI or multiple environments. The catch is that Terraform can't cleanly
          create its own backend on the very first run — because it needs somewhere to store state before it can manage anything.
        </Paragraph>

        <Paragraph>
          That's why this template includes a tiny CLI. It bootstraps the prerequisites using CloudFormation (idempotent, safe to rerun),
          then generates a backend config file so <InlineHighlight>terraform init</InlineHighlight> works immediately.
        </Paragraph>

        <CodeBlockWithCopy code={bootstrapOverview} />

        <SubSectionHeading>What gets created</SubSectionHeading>

        <TextList>
          <TextListItem>
            <Strong>S3 state bucket</Strong> — versioning enabled, encryption on, and public access blocked.
          </TextListItem>
          <TextListItem>
            <Strong>DynamoDB lock table</Strong> — prevents concurrent applies from corrupting state.
          </TextListItem>
          <TextListItem>
            <Strong>Terraform execution role</Strong> — assumed locally (profiles) and/or by CI via OIDC.
          </TextListItem>
        </TextList>

        <SubSectionHeading>Run the bootstrap</SubSectionHeading>
        <CodeBlockWithCopy code={bootstrapCommands} />

        <SubSectionHeading>Generated backend config</SubSectionHeading>

        <Paragraph>
          Instead of hardcoding backend values in <InlineHighlight>backend.tf</InlineHighlight>, the CLI generates an{" "}
          <InlineHighlight>infra/backend.hcl</InlineHighlight> file and we initialise Terraform with it.
          This keeps environment/account details out of Git, and makes the template portable.
        </Paragraph>

        <CodeCarousel
          items={[
            {
              title: "infra/backend.hcl",
              description: "Generated by the CLI (gitignored). Contains real bucket/table/role values.",
              code: backendHclExample,
            },
            {
              title: "backend.tf (recommended)",
              description: "Backend block stays minimal so config is injected at init time.",
              code: backendTfRecommended,
            },
            {
              title: "package.json scripts",
              description: "Convenience scripts so bootstrapping is a single command.",
              code: packageJsonScripts,
            },
          ]}
        />

        <Paragraph>
          One important template detail: the bootstrap step is intentionally <Strong>single-account</Strong>. It creates resources in
          whichever AWS account your credentials point at. If you want to bootstrap a second account, switch AWS context and run it again.
        </Paragraph>

        <CodeBlockWithCopy code={namingAndSingleAccountNote} />

        <SectionHeading>GitHub Actions: plan on PR, apply on main</SectionHeading>

        <Paragraph>
          Once your repo structure is in place and you've got an execution role per environment, GitHub Actions becomes the glue that makes Terraform feel
          safe and repeatable. The goal is simple:
        </Paragraph>

        <TextList>
          <TextListItem>
            <Strong>Pull requests</Strong> generate plans automatically for each environment, so changes are reviewed like code.
          </TextListItem>
          <TextListItem>
            <Strong>Applies</Strong> are triggered manually with <InlineHighlight>workflow_dispatch</InlineHighlight>, so deployments are always intentional.
          </TextListItem>
          <TextListItem>
            <Strong>Sensitive environments</Strong> should be protected with required reviewers via GitHub Environments.
          </TextListItem>
        </TextList>

        <SubSectionHeading>Authenticating to AWS (OIDC)</SubSectionHeading>

        <Paragraph>
          For CI, the cleanest pattern is to use GitHub's OIDC integration to assume an AWS role with short-lived credentials. That means you don't need to store
          long-lived AWS access keys in GitHub secrets. GitHub and AWS both document this approach, and the{" "}
          <InlineHighlight>aws-actions/configure-aws-credentials</InlineHighlight> action supports it directly.
        </Paragraph>

        <Paragraph>
          The only requirement on the workflow side is granting <InlineHighlight>id-token: write</InlineHighlight> so the job can request an OIDC token.
        </Paragraph>

        <SubSectionHeading>Environment protection for sensitive environments</SubSectionHeading>

        <Paragraph>
          GitHub Environments let you put guardrails around deployments. If an environment is sensitive, you can require reviewers so any apply job targeting that
          environment pauses until someone approves. This gives you a clean manual approval step without custom logic.
        </Paragraph>

        <SubSectionHeading>The workflow</SubSectionHeading>

        <Paragraph>
          The workflow below follows the same shape as our local scripts:
          <InlineHighlight> validate </InlineHighlight> → <InlineHighlight> plan </InlineHighlight> → <InlineHighlight> apply </InlineHighlight>.
          On pull requests, it runs <Strong>validate + plan</Strong> for each environment in the matrix and uploads the plan output as an artifact.
          Applies are triggered manually via <InlineHighlight>workflow_dispatch</InlineHighlight> and run under a GitHub Environment named after the environment.
        </Paragraph>

        <CodeBlockWithCopy code={githubTerraformWorkflow} />

        <Paragraph>
          Under the hood, we rely on <InlineHighlight>hashicorp/setup-terraform</InlineHighlight> to install Terraform on the runner, and we use OIDC auth to assume
          the correct Terraform execution role for each environment.
        </Paragraph>

        <SectionHeading>GitHub repo setup (Environments, approvals, secrets)</SectionHeading>

        <Paragraph>
          The workflow is only half the story. To make Terraform safe in CI, you need a small amount of GitHub repo configuration:
          GitHub Environments (for approvals + scoping secrets) and a place to store the AWS role ARN that GitHub will assume via OIDC.
        </Paragraph>

        <Paragraph>
          In this template, we treat each folder under <InlineHighlight>infra/env/</InlineHighlight> as a deployable environment. In CI, that same environment name is used as a
          GitHub Environment. This keeps everything consistent and makes it harder to apply to the wrong place accidentally.
        </Paragraph>

        <SubSectionHeading>1) Create GitHub Environments to match your aws accounts</SubSectionHeading>

        <Paragraph>
          Create one GitHub Environment per environment. The environment name should match the folder name under <InlineHighlight>infra/env/</InlineHighlight> exactly.
        </Paragraph>

        <IndentedTextList>
          <IndentedTextListItem>
            Go to <Strong>Settings</Strong>
          </IndentedTextListItem>
          <IndentedTextListItem>
            In the left sidebar, click <Strong>Environments</Strong>
          </IndentedTextListItem>
          <IndentedTextListItem>
            Click <Strong>New environment</Strong>
          </IndentedTextListItem>
          <IndentedTextListItem>
            Create an environment named exactly the same as your environment folder (for example: <InlineHighlight>account-a</InlineHighlight>)
          </IndentedTextListItem>
          <IndentedTextListItem>
            Repeat for each environment folder under <InlineHighlight>infra/env/</InlineHighlight>
          </IndentedTextListItem>
        </IndentedTextList>

        <Paragraph>
          If your workflow uses<InlineHighlight>{'environment: ${{ inputs.environment }}'}</InlineHighlight>, then when you trigger an apply for a environment,
          GitHub automatically scopes secrets and approvals to the matching Environment.
        </Paragraph>

        <SubSectionHeading>2) Add manual approvals for sensitive environments</SubSectionHeading>

        <Paragraph>
          GitHub Environments let you add guardrails around deployments. If a environment is sensitive, you can require reviewers so applies pause until someone approves.
          GitHub calls these <Strong>deployment protection rules</Strong>.
        </Paragraph>

        <Paragraph>
          In your repo:
        </Paragraph>

        <IndentedTextList>
          <IndentedTextListItem>
            Go to <Strong>Settings</Strong> → <Strong>Environments</Strong>
          </IndentedTextListItem>
          <IndentedTextListItem>
            Click the environment for your sensitive environment (for example: <InlineHighlight>account-b</InlineHighlight>)
          </IndentedTextListItem>
          <IndentedTextListItem>
            Under <Strong>Deployment protection rules</Strong>, enable <Strong>Required reviewers</Strong>
          </IndentedTextListItem>
          <IndentedTextListItem>
            Add yourself (or a team) as a required reviewer
          </IndentedTextListItem>
        </IndentedTextList>

        <Paragraph>
          Now, any job that targets that Environment will pause and wait for approval before it can run.
        </Paragraph>

        <SubSectionHeading>3) Add the AWS role ARN as an Environment secret</SubSectionHeading>

        <Paragraph>
          The workflow needs an IAM role ARN to assume via OIDC. The cleanest pattern is to store this as an{" "}
          <Strong>Environment secret</Strong> so each environment can assume its own role without you hardcoding values in the workflow.
        </Paragraph>

        <Paragraph>
          For each GitHub Environment you created:
        </Paragraph>

        <IndentedTextList>
          <IndentedTextListItem>
            Go to <Strong>Settings</Strong> → <Strong>Environments</Strong>
          </IndentedTextListItem>
          <IndentedTextListItem>
            Click the environment that matches your environment folder (for example: <InlineHighlight>account-a</InlineHighlight>)
          </IndentedTextListItem>
          <IndentedTextListItem>
            Under <Strong>Environment secrets</Strong>, click <Strong>Add secret</Strong>
          </IndentedTextListItem>
          <IndentedTextListItem>
            Add <InlineHighlight>AWS_ROLE_ARN</InlineHighlight> = <InlineHighlight>arn:aws:iam::...:role/&lt;terraform-execution-role&gt;</InlineHighlight>
          </IndentedTextListItem>
          <IndentedTextListItem>
            Repeat for each target environment with that target's role ARN
          </IndentedTextListItem>
        </IndentedTextList>

        <Paragraph>
          Because the secret name is the same everywhere (<InlineHighlight>AWS_ROLE_ARN</InlineHighlight>), the workflow stays simple and GitHub automatically supplies
          the correct value based on the target environment.
        </Paragraph>

        <SubSectionHeading>4) What it looks like when an apply is waiting for approval</SubSectionHeading>

        <Paragraph>
          When you trigger an apply for a protected target, the workflow run will pause at "Deployment protection rules" and wait. A reviewer can then approve and start
          the waiting job directly from the workflow run page.
        </Paragraph>

        <IndentedTextList>
          <IndentedTextListItem>
            Go to the <Strong>Actions</Strong> tab
          </IndentedTextListItem>
          <IndentedTextListItem>
            Open the running workflow
          </IndentedTextListItem>
          <IndentedTextListItem>
            In <Strong>Deployment protection rules</Strong>, click <Strong>Review deployments</Strong> / <Strong>Start all waiting jobs</Strong> (wording varies)
          </IndentedTextListItem>
        </IndentedTextList>

        <SubSectionHeading>5) Sanity check: OIDC permissions</SubSectionHeading>

        <Paragraph>
          For OIDC to work, your workflow must have <InlineHighlight>permissions: id-token: write</InlineHighlight>. Without it, GitHub can't use the OIDC token
          and the AWS credentials step won't be able to assume the role.
        </Paragraph>

        <Paragraph>
          If you see auth errors in CI, the first things to check are:
        </Paragraph>

        <TextList>
          <TextListItem>
            <Strong>The job has id-token: write</Strong> in workflow permissions
          </TextListItem>
          <TextListItem>
            <Strong>The IAM role trust policy</Strong> allows your GitHub repo/org to assume the role via OIDC
          </TextListItem>
          <TextListItem>
            <Strong>The environment secret exists</Strong> (AWS_ROLE_ARN) for the target you're trying to run
          </TextListItem>
        </TextList>

      </AnimatedPostContainer>
    </PageWrapper >
  );
}

export default IaCTerraform;
